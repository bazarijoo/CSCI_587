{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynMhPmd5_0Rk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 3: Spatiotemporal Traffic Forecasting using DCRNN\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this assignment, you will use LA traffic sensor data to explore how different graph structures impact the performance of the [Diffusion Convolutional Recurrent Neural Network (DCRNN)](https://arxiv.org/abs/1707.01926) for traffic forecasting. By the end of this assignment, you should have a deeper understanding of:\n",
    "1. How different graph structures can influence forecasting accuracy of GNN-based approaches.\n",
    "2. How to design an end-to-end approach to train and evaluate a model for spatiotemporal forecasting.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "You will:\n",
    "- Train and test the DCRNN on several graph structures, including:\n",
    "  - **Euclidean Distance**: Graph nodes are connected based on the Euclidean distances between traffic sensors.\n",
    "  - **Road-Network Distance**: Graph nodes are connected based on actual road-network distances between sensors.\n",
    "  - **Fully Connected**: All nodes are connected to each other.\n",
    "  - **Fully Disconnected (Identity Matrix)**: Each node is only connected to itself, meaning the model does not leverage information from neighboring nodes for predictions.\n",
    "  - **Correlation across Time Series**: Connections are based on correlation in traffic patterns across sensors. This means the graph changes dynamically per each time window.\n",
    "\n",
    "- Compare the model performance across these structures.\n",
    "- Analyze why certain graph structures may perform better than others for forecasting traffic patterns.\n",
    "\n",
    "### Dataset Overview\n",
    "\n",
    "The dataset consists of traffic flow readings (average speed of cars passing the sensors over a specific time interval) from various sensors across LA. Each sensor represents a node, and traffic flow measurements are recorded at regular time intervals, providing a temporal sequence for each node.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Fill in the missing code sections and write your explanations/analysis as required to complete the tasks. Good luck and have fun! Don't forget you can always reach out to the TAs if you need clarifications on the following tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBYyaTCnB6hp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "In this section, you will load the METR-LA traffic dataset and preprocess it to prepare it for model input. METR-LA consists of traffic speed data from sensors across Los Angeles County, recorded at 5-minute intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKt6xjL6DJo-",
    "outputId": "e1523905-247a-4d84-b1a7-6aa1f72cd0e4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "URLs for the data files\n",
    "sensors_url = \"https://github.com/tijsmaas/TrafficPrediction/raw/master/data/metr-la/graph_sensor_locations.csv\"\n",
    "traffic_url = \"https://github.com/TrafficGCN/ST-GCN/raw/refs/heads/main/data/metr-la/traffic/speed.csv\"\n",
    "\n",
    "# Download and save the sensor locations data\n",
    "csv_response = requests.get(sensors_url)\n",
    "with open(\"data/graph_sensor_locations.csv\", \"wb\") as f:\n",
    "    f.write(csv_response.content)\n",
    "\n",
    "# Download and save the traffic data\n",
    "csv_response = requests.get(traffic_url)\n",
    "with open(\"data/metr-la.csv\", \"wb\") as f:\n",
    "    f.write(csv_response.content)\n",
    "\n",
    "print(\"Files downloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9naVj4gKjTj",
    "outputId": "cf6b88c6-06d2-453e-adfd-4be0d2ad1846",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor Locations Data:\n",
      "    index  sensor_id  latitude  longitude\n",
      "0      0     773869  34.15497 -118.31829\n",
      "1      1     767541  34.11621 -118.23799\n",
      "2      2     767542  34.11641 -118.23819\n",
      "3      3     717447  34.07248 -118.26772\n",
      "4      4     717446  34.07142 -118.26572\n",
      "\n",
      "Traffic Data:\n",
      "          DATETIMESTAMP     773869     767541     767542     717447     717446  \\\n",
      "0  2012-03-01 00:00:00  64.375000  67.625000  67.125000  61.500000  66.875000   \n",
      "1  2012-03-01 00:05:00  62.666667  68.555556  65.444444  62.444444  64.444444   \n",
      "2  2012-03-01 00:10:00  64.000000  63.750000  60.000000  59.000000  66.500000   \n",
      "3  2012-03-01 00:25:00  57.333333  69.000000  67.666667  61.666667  67.333333   \n",
      "4  2012-03-01 00:30:00  66.500000  63.875000  67.875000  62.375000  64.375000   \n",
      "\n",
      "      717445     773062     767620     737529  ...     772167  769372  \\\n",
      "0  68.750000  65.125000  67.125000  59.625000  ...  45.625000  65.500   \n",
      "1  68.111111  65.000000  65.000000  57.444444  ...  50.666667  69.875   \n",
      "2  66.250000  64.500000  64.250000  63.875000  ...  44.125000  69.000   \n",
      "3  69.000000  60.666667  67.333333  63.000000  ...  42.000000  70.000   \n",
      "4  67.750000  65.125000  64.875000  56.250000  ...  41.250000  69.375   \n",
      "\n",
      "      774204     769806  717590     717592     717595     772168     718141  \\\n",
      "0  64.500000  66.428571  66.875  59.375000  69.000000  59.250000  69.000000   \n",
      "1  66.666667  58.555556  62.000  61.111111  64.444444  55.888889  68.444444   \n",
      "2  56.500000  59.250000  68.125  62.500000  65.625000  61.375000  69.857143   \n",
      "3  68.333333  57.333333  66.000  54.666667  64.666667  57.666667  69.000000   \n",
      "4  59.500000  44.625000  64.250  62.625000  65.500000  51.000000  69.375000   \n",
      "\n",
      "      769373  \n",
      "0  61.875000  \n",
      "1  62.875000  \n",
      "2  62.000000  \n",
      "3  57.333333  \n",
      "4  61.250000  \n",
      "\n",
      "[5 rows x 208 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the sensor locations CSV file\n",
    "sensor_locations = pd.read_csv(\"data/graph_sensor_locations.csv\")\n",
    "print(\"Sensor Locations Data:\\n\", sensor_locations.head())\n",
    "\n",
    "# Load the METR-LA traffic data\n",
    "traffic_df = pd.read_csv(\"data/metr-la.csv\")\n",
    "print(\"\\nTraffic Data:\\n\", traffic_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zz_Va5RJO6q-",
    "outputId": "c853c360-6f1b-4dcd-c17e-c437501dfca0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnormalized Sensor Data:\n",
      "       773869     767541     767542     717447     717446     717445  \\\n",
      "0  64.375000  67.625000  67.125000  61.500000  66.875000  68.750000   \n",
      "1  62.666667  68.555556  65.444444  62.444444  64.444444  68.111111   \n",
      "2  64.000000  63.750000  60.000000  59.000000  66.500000  66.250000   \n",
      "3  57.333333  69.000000  67.666667  61.666667  67.333333  69.000000   \n",
      "4  66.500000  63.875000  67.875000  62.375000  64.375000  67.750000   \n",
      "\n",
      "      773062     767620     737529     717816  ...     772167  769372  \\\n",
      "0  65.125000  67.125000  59.625000  62.750000  ...  45.625000  65.500   \n",
      "1  65.000000  65.000000  57.444444  63.333333  ...  50.666667  69.875   \n",
      "2  64.500000  64.250000  63.875000  65.375000  ...  44.125000  69.000   \n",
      "3  60.666667  67.333333  63.000000  63.333333  ...  42.000000  70.000   \n",
      "4  65.125000  64.875000  56.250000  63.000000  ...  41.250000  69.375   \n",
      "\n",
      "      774204     769806  717590     717592     717595     772168     718141  \\\n",
      "0  64.500000  66.428571  66.875  59.375000  69.000000  59.250000  69.000000   \n",
      "1  66.666667  58.555556  62.000  61.111111  64.444444  55.888889  68.444444   \n",
      "2  56.500000  59.250000  68.125  62.500000  65.625000  61.375000  69.857143   \n",
      "3  68.333333  57.333333  66.000  54.666667  64.666667  57.666667  69.000000   \n",
      "4  59.500000  44.625000  64.250  62.625000  65.500000  51.000000  69.375000   \n",
      "\n",
      "      769373  \n",
      "0  61.875000  \n",
      "1  62.875000  \n",
      "2  62.000000  \n",
      "3  57.333333  \n",
      "4  61.250000  \n",
      "\n",
      "[5 rows x 207 columns]\n",
      "\n",
      "\n",
      "Normalized Traffic Data:\n",
      "          DATETIMESTAMP    773869    767541    767542    717447    717446  \\\n",
      "0  2012-03-01 00:00:00  0.919643  0.966071  0.958929  0.878571  0.955357   \n",
      "1  2012-03-01 00:05:00  0.895238  0.979365  0.934921  0.892063  0.920635   \n",
      "2  2012-03-01 00:10:00  0.914286  0.910714  0.857143  0.842857  0.950000   \n",
      "3  2012-03-01 00:25:00  0.819048  0.985714  0.966667  0.880952  0.961905   \n",
      "4  2012-03-01 00:30:00  0.950000  0.912500  0.969643  0.891071  0.919643   \n",
      "\n",
      "     717445    773062    767620    737529  ...    772167    769372    774204  \\\n",
      "0  0.982143  0.930357  0.958929  0.851786  ...  0.701923  0.935714  0.921429   \n",
      "1  0.973016  0.928571  0.928571  0.820635  ...  0.779487  0.998214  0.952381   \n",
      "2  0.946429  0.921429  0.917857  0.912500  ...  0.678846  0.985714  0.807143   \n",
      "3  0.985714  0.866667  0.961905  0.900000  ...  0.646154  1.000000  0.976190   \n",
      "4  0.967857  0.930357  0.926786  0.803571  ...  0.634615  0.991071  0.850000   \n",
      "\n",
      "     769806    717590    717592    717595    772168    718141    769373  \n",
      "0  0.948980  0.955357  0.848214  0.985714  0.846429  0.985714  0.883929  \n",
      "1  0.836508  0.885714  0.873016  0.920635  0.798413  0.977778  0.898214  \n",
      "2  0.846429  0.973214  0.892857  0.937500  0.876786  0.997959  0.885714  \n",
      "3  0.819048  0.942857  0.780952  0.923810  0.823810  0.985714  0.819048  \n",
      "4  0.637500  0.917857  0.894643  0.935714  0.728571  0.991071  0.875000  \n",
      "\n",
      "[5 rows x 208 columns]\n"
     ]
    }
   ],
   "source": [
    "# Separate the datetime column from the sensor data\n",
    "datetime_column = traffic_df.iloc[:, 0]  # the first column is datetime\n",
    "sensor_data = traffic_df.iloc[:, 1:]  # All other columns are sensor data\n",
    "print(\"Unnormalized Sensor Data:\\n\", sensor_data.head())\n",
    "\n",
    "# Normalize the traffic speed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_sensor_data = scaler.fit_transform(sensor_data)\n",
    "\n",
    "# Convert normalized data back to a DataFrame\n",
    "normalized_sensor_df = pd.DataFrame(normalized_sensor_data, columns=sensor_data.columns)\n",
    "\n",
    "# Add back the datetime column just in case\n",
    "normalized_traffic_df = pd.concat([datetime_column, normalized_sensor_df], axis=1)\n",
    "print(\"\\n\\nNormalized Traffic Data:\\n\", normalized_traffic_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU5Ope5Dr32d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we define a dataset class so as to manage the traffic samples more easily for training DCRNN. This class basically prepares windows of traffic observations as the input to the model, and provides the ground truth future traffic observations for the specified horizon to calculate the forecasting error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CFutQ0HzSf1C",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here, we define a traffic dataset class to easily get METR-LA samples\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, traffic_df, sensor_df, window_size, horizon):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            traffic_df (pd.DataFrame): Normalized traffic data with datetime as the first column.\n",
    "            sensor_df (pd.DataFrame): Sensor locations or metadata.\n",
    "            window_size (int): Number of time steps in each input sequence.\n",
    "            horizon (int): Number of time steps ahead to predict.\n",
    "        \"\"\"\n",
    "        self.datetime = traffic_df.iloc[:, 0]  # Store datetime separately just in case\n",
    "        self.data = traffic_df.iloc[:, 1:].values.reshape(-1, traffic_df.shape[1] - 1, 1)  # Shape (num_samples, num_sensors, num_features)\n",
    "        \n",
    "        # Store sensor locations data for future adjacency calculations\n",
    "        self.sensor_df = sensor_df\n",
    "\n",
    "        # Sliding window and horizon\n",
    "        self.window_size = window_size\n",
    "        self.horizon = horizon\n",
    "\n",
    "    def __len__(self):\n",
    "        # Total samples is reduced by window size + horizon to ensure complete sequences\n",
    "        return len(self.data) - self.window_size - self.horizon + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Define input window (past sequence) and target (future value)\n",
    "        x = self.data[idx : idx + self.window_size]\n",
    "        y = self.data[idx + self.window_size : idx + self.window_size + self.horizon]\n",
    "\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seC0Fbe0sNEb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the next step, we divide the traffic data into train/validation/test folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8j08eVgT-ZP",
    "outputId": "532a889a-2687-4487-b87c-c14c791a46e5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (22491, 208)\n",
      "Validation data shape: (4830, 208)\n",
      "Test data shape: (4831, 208)\n"
     ]
    }
   ],
   "source": [
    "# Next, we split the data into train/val/test\n",
    "window_size = 12\n",
    "horizon = 3\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Calculate split indices\n",
    "num_samples = len(traffic_df) - window_size - horizon + 1 # replace traffic_df with normalized_traffic_df\n",
    "train_size = int(train_ratio * num_samples)\n",
    "val_size = int(val_ratio * num_samples)\n",
    "\n",
    "# Split the traffic data into train, validation, and test sets\n",
    "train_data = traffic_df.iloc[:train_size + window_size + horizon - 1]\n",
    "val_data = traffic_df.iloc[train_size:train_size + val_size + window_size + horizon - 1]\n",
    "test_data = traffic_df.iloc[train_size + val_size:]\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {val_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# Initialize dataset instances\n",
    "train_dataset = TrafficDataset(traffic_df=train_data, sensor_df=sensor_locations, window_size=window_size, horizon=horizon)\n",
    "val_dataset = TrafficDataset(traffic_df=val_data, sensor_df=sensor_locations, window_size=window_size, horizon=horizon)\n",
    "test_dataset = TrafficDataset(traffic_df=test_data, sensor_df=sensor_locations, window_size=window_size, horizon=horizon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo8yfd_-seu-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we initialize data loaders to get batches of samples from datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKhWJbKVUOAw",
    "outputId": "829bdf71-8e44-4ddd-da0f-31c7ca3536c9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 352\n",
      "Number of validation batches: 76\n",
      "Number of test batches: 76\n"
     ]
    }
   ],
   "source": [
    "# Here, we set up our dataloaders\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mguzuFJ2X_z_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model\n",
    "Here, we add the DCRNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0NuZIiUeUcGX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Next, we set up the DCRNN model\n",
    "\"\"\"\n",
    "Codes are adapted from https://github.com/liyaguang/DCRNN\n",
    "and https://github.com/xlwang233/pytorch-DCRNN and https://github.com/tsy935/eeg-gnn-ssl, which are\n",
    "licensed under the MIT License.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "\n",
    "def compute_sampling_threshold(cl_decay_steps, global_step):\n",
    "    \"\"\"\n",
    "    Compute scheduled sampling threshold\n",
    "    \"\"\"\n",
    "    return cl_decay_steps / \\\n",
    "        (cl_decay_steps + np.exp(global_step / cl_decay_steps))\n",
    "        \n",
    "        \n",
    "def calculate_normalized_laplacian(adj):\n",
    "    \"\"\"\n",
    "    # L = D^-1/2 (D-A) D^-1/2 = I - D^-1/2 A D^-1/2\n",
    "    # D = diag(A 1)\n",
    "    :param adj:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    d = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(d, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    normalized_laplacian = sp.eye(adj.shape[0]) - adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "    return normalized_laplacian.toarray()\n",
    "\n",
    "\n",
    "def calculate_random_walk_matrix(adj_mx):\n",
    "    adj_mx = sp.coo_matrix(adj_mx)\n",
    "    d = np.array(adj_mx.sum(1))\n",
    "    d_inv = np.power(d, -1).flatten()\n",
    "    d_inv[np.isinf(d_inv)] = 0.\n",
    "    d_mat_inv = sp.diags(d_inv)\n",
    "    random_walk_mx = d_mat_inv.dot(adj_mx).tocoo()\n",
    "    return torch.tensor(random_walk_mx.toarray())\n",
    "\n",
    "\n",
    "def calculate_reverse_random_walk_matrix(adj_mx):\n",
    "    return calculate_random_walk_matrix(np.transpose(adj_mx))\n",
    "\n",
    "class DiffusionGraphConv(nn.Module):\n",
    "    def __init__(self, num_supports, input_dim, hid_dim, num_nodes,\n",
    "                 max_diffusion_step, output_dim, bias_start=0.0,\n",
    "                 filter_type='laplacian'):\n",
    "        \"\"\"\n",
    "        Diffusion graph convolution\n",
    "        Args:\n",
    "            num_supports: number of supports, 1 for 'laplacian' filter and 2\n",
    "                for 'dual_random_walk'\n",
    "            input_dim: input feature dim\n",
    "            hid_dim: hidden units\n",
    "            num_nodes: number of nodes in graph\n",
    "            max_diffusion_step: maximum diffusion step\n",
    "            output_dim: output feature dim\n",
    "            filter_type: 'laplacian' for undirected graph, and 'dual_random_walk'\n",
    "                for directed graph\n",
    "        \"\"\"\n",
    "        super(DiffusionGraphConv, self).__init__()\n",
    "        self._num_supports = num_supports\n",
    "        self._num_matrices = num_supports * max_diffusion_step + 1\n",
    "        self._input_size = input_dim + hid_dim\n",
    "        self._num_nodes = num_nodes\n",
    "        self._max_diffusion_step = max_diffusion_step\n",
    "        self._filter_type = filter_type\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.FloatTensor(\n",
    "                size=(\n",
    "                    self._input_size *\n",
    "                    self._num_matrices,\n",
    "                    output_dim)))\n",
    "        self.biases = nn.Parameter(torch.FloatTensor(size=(output_dim,)))\n",
    "        nn.init.xavier_normal_(self.weight.data, gain=1.414)\n",
    "        nn.init.constant_(self.biases.data, val=bias_start)\n",
    "\n",
    "    @staticmethod\n",
    "    def _concat(x, x_):\n",
    "        x_ = torch.unsqueeze(x_, 1)\n",
    "        return torch.cat([x, x_], dim=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_sparse_matrix(L):\n",
    "        \"\"\"\n",
    "        build pytorch sparse tensor from scipy sparse matrix\n",
    "        reference: https://stackoverflow.com/questions/50665141\n",
    "        \"\"\"\n",
    "        shape = L.shape\n",
    "        i = torch.LongTensor(np.vstack((L.row, L.col)).astype(int))\n",
    "        v = torch.FloatTensor(L.data)\n",
    "        return torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "\n",
    "    def forward(self, supports, inputs, state, output_size, bias_start=0.0):\n",
    "        # Reshape input and state to (batch_size, num_nodes,\n",
    "        # input_dim/hidden_dim)\n",
    "        batch_size = inputs.shape[0]\n",
    "        inputs = torch.reshape(inputs, (batch_size, self._num_nodes, -1))\n",
    "        state = torch.reshape(state, (batch_size, self._num_nodes, -1))\n",
    "        # (batch, num_nodes, input_dim+hidden_dim)\n",
    "        inputs_and_state = torch.cat([inputs, state], dim=2)\n",
    "        input_size = inputs_and_state.shape[2]\n",
    "\n",
    "        x0 = inputs_and_state  # (batch, num_nodes, input_dim+hidden_dim)\n",
    "        # (batch, 1, num_nodes, input_dim+hidden_dim)\n",
    "        x = torch.unsqueeze(x0, dim=1)\n",
    "        \n",
    "        # generate reverse random walk matrix\n",
    "\n",
    "        if self._max_diffusion_step == 0:\n",
    "            pass\n",
    "        else:\n",
    "            for support in supports:\n",
    "                # (batch, num_nodes, input_dim+hidden_dim)\n",
    "                x1 = torch.matmul(support, x0)\n",
    "                # (batch, ?, num_nodes, input_dim+hidden_dim)\n",
    "                x = self._concat(x, x1)\n",
    "                for k in range(2, self._max_diffusion_step + 1):\n",
    "                    # (batch, num_nodes, input_dim+hidden_dim)\n",
    "                    x2 = 2 * torch.matmul(support, x1) - x0\n",
    "                    x = self._concat(\n",
    "                        x, x2)  # (batch, ?, num_nodes, input_dim+hidden_dim)\n",
    "                    x1, x0 = x2, x1\n",
    "                    \n",
    "        num_matrices = len(supports) * \\\n",
    "            self._max_diffusion_step + 1  # Adds for x itself\n",
    "            \n",
    "        # (batch, num_nodes, num_matrices, input_hidden_size)\n",
    "        x = torch.transpose(x, dim0=1, dim1=2)\n",
    "        # (batch, num_nodes, input_hidden_size, num_matrices)\n",
    "        x = torch.transpose(x, dim0=2, dim1=3)\n",
    "        x = torch.reshape(\n",
    "            x,\n",
    "            shape=[\n",
    "                batch_size,\n",
    "                self._num_nodes,\n",
    "                input_size *\n",
    "                self._num_matrices])\n",
    "        x = torch.reshape(\n",
    "            x,\n",
    "            shape=[\n",
    "                batch_size *\n",
    "                self._num_nodes,\n",
    "                input_size *\n",
    "                self._num_matrices])\n",
    "\n",
    "        # (batch_size * self._num_nodes, output_size)\n",
    "        x = torch.matmul(x, self.weight)\n",
    "        x = torch.add(x, self.biases)\n",
    "        x = torch.reshape(x, [batch_size, self._num_nodes * output_size])\n",
    "        return x\n",
    "\n",
    "class DCGRUCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Convolution Gated Recurrent Unit Cell.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            num_units,\n",
    "            max_diffusion_step,\n",
    "            num_nodes,\n",
    "            filter_type=\"laplacian\",\n",
    "            nonlinearity='tanh',\n",
    "            use_gc_for_ru=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: input feature dim\n",
    "            num_units: number of DCGRU hidden units\n",
    "            max_diffusion_step: maximum diffusion step\n",
    "            num_nodes: number of nodes in the graph\n",
    "            filter_type: 'laplacian' for undirected graph, 'dual_random_walk' for directed graph\n",
    "            nonlinearity: 'tanh' or 'relu'. Default is 'tanh'\n",
    "            use_gc_for_ru: decide whether to use graph convolution inside rnn. Default True\n",
    "        \"\"\"\n",
    "        super(DCGRUCell, self).__init__()\n",
    "        self._activation = torch.tanh if nonlinearity == 'tanh' else torch.relu\n",
    "        self._num_nodes = num_nodes\n",
    "        self._num_units = num_units\n",
    "        self._max_diffusion_step = max_diffusion_step\n",
    "        self._use_gc_for_ru = use_gc_for_ru\n",
    "        if filter_type == \"laplacian\":  # ChebNet graph conv\n",
    "            self._num_supports = 1\n",
    "        elif filter_type == \"random_walk\":  # Forward random walk\n",
    "            self._num_supports = 1\n",
    "        elif filter_type == \"dual_random_walk\":  # Bidirectional random walk\n",
    "            self._num_supports = 2\n",
    "        else:\n",
    "            self._num_supports = 1\n",
    "\n",
    "        self.dconv_gate = DiffusionGraphConv(\n",
    "            num_supports=self._num_supports,\n",
    "            input_dim=input_dim,\n",
    "            hid_dim=num_units,\n",
    "            num_nodes=num_nodes,\n",
    "            max_diffusion_step=max_diffusion_step,\n",
    "            output_dim=num_units * 2,\n",
    "            filter_type=filter_type)\n",
    "        self.dconv_candidate = DiffusionGraphConv(\n",
    "            num_supports=self._num_supports,\n",
    "            input_dim=input_dim,\n",
    "            hid_dim=num_units,\n",
    "            num_nodes=num_nodes,\n",
    "            max_diffusion_step=max_diffusion_step,\n",
    "            output_dim=num_units,\n",
    "            filter_type=filter_type)\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        output_size = self._num_nodes * self._num_units\n",
    "        return output_size\n",
    "\n",
    "    def forward(self, supports, inputs, state):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: (B, num_nodes * input_dim)\n",
    "            state: (B, num_nodes * num_units)\n",
    "        Returns:\n",
    "            output: (B, num_nodes * output_dim)\n",
    "            state: (B, num_nodes * num_units)\n",
    "        \"\"\"\n",
    "        output_size = 2 * self._num_units\n",
    "        if self._use_gc_for_ru:\n",
    "            fn = self.dconv_gate\n",
    "        else:\n",
    "            fn = self._fc\n",
    "        value = torch.sigmoid(\n",
    "            fn(supports, inputs, state, output_size, bias_start=1.0))\n",
    "        value = torch.reshape(value, (-1, self._num_nodes, output_size))\n",
    "        r, u = torch.split(\n",
    "            value, split_size_or_sections=int(\n",
    "                output_size / 2), dim=-1)\n",
    "        r = torch.reshape(r, (-1, self._num_nodes * self._num_units))\n",
    "        u = torch.reshape(u, (-1, self._num_nodes * self._num_units))\n",
    "        # batch_size, self._num_nodes * output_size\n",
    "        c = self.dconv_candidate(supports, inputs, r * state, self._num_units)\n",
    "        if self._activation is not None:\n",
    "            c = self._activation(c)\n",
    "        output = new_state = u * state + (1 - u) * c\n",
    "\n",
    "        return output, new_state\n",
    "\n",
    "    @staticmethod\n",
    "    def _concat(x, x_):\n",
    "        x_ = torch.unsqueeze(x_, 0)\n",
    "        return torch.cat([x, x_], dim=0)\n",
    "\n",
    "    def _gconv(self, supports, inputs, state, output_size, bias_start=0.0):\n",
    "        pass\n",
    "\n",
    "    def _fc(self, supports, inputs, state, output_size, bias_start=0.0):\n",
    "        pass\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # state: (B, num_nodes * num_units)\n",
    "        return torch.zeros(batch_size, self._num_nodes * self._num_units)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DCRNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, max_diffusion_step,\n",
    "                 hid_dim, num_nodes, num_rnn_layers,\n",
    "                 dcgru_activation=None, filter_type='laplacian',\n",
    "                 device=None):\n",
    "        super(DCRNNEncoder, self).__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_rnn_layers = num_rnn_layers\n",
    "        self._device = device\n",
    "\n",
    "        encoding_cells = list()\n",
    "        # the first layer has different input_dim\n",
    "        encoding_cells.append(\n",
    "            DCGRUCell(\n",
    "                input_dim=input_dim,\n",
    "                num_units=hid_dim,\n",
    "                max_diffusion_step=max_diffusion_step,\n",
    "                num_nodes=num_nodes,\n",
    "                nonlinearity=dcgru_activation,\n",
    "                filter_type=filter_type))\n",
    "\n",
    "        # construct multi-layer rnn\n",
    "        for _ in range(1, num_rnn_layers):\n",
    "            encoding_cells.append(\n",
    "                DCGRUCell(\n",
    "                    input_dim=hid_dim,\n",
    "                    num_units=hid_dim,\n",
    "                    max_diffusion_step=max_diffusion_step,\n",
    "                    num_nodes=num_nodes,\n",
    "                    nonlinearity=dcgru_activation,\n",
    "                    filter_type=filter_type))\n",
    "        self.encoding_cells = nn.ModuleList(encoding_cells)\n",
    "\n",
    "    def forward(self, inputs, initial_hidden_state, supports):\n",
    "        seq_length = inputs.shape[0]\n",
    "        batch_size = inputs.shape[1]\n",
    "        # (seq_length, batch_size, num_nodes*input_dim)\n",
    "        inputs = torch.reshape(inputs, (seq_length, batch_size, -1))\n",
    "\n",
    "        current_inputs = inputs\n",
    "        # the output hidden states, shape (num_layers, batch, outdim)\n",
    "        output_hidden = []\n",
    "        for i_layer in range(self.num_rnn_layers):\n",
    "            hidden_state = initial_hidden_state[i_layer]\n",
    "            output_inner = []\n",
    "            for t in range(seq_length):\n",
    "                _, hidden_state = self.encoding_cells[i_layer](\n",
    "                    supports, current_inputs[t, ...], hidden_state)\n",
    "                output_inner.append(hidden_state)\n",
    "            output_hidden.append(hidden_state)\n",
    "            current_inputs = torch.stack(output_inner, dim=0).to(\n",
    "                self._device)  # (seq_len, batch_size, num_nodes * rnn_units)\n",
    "        output_hidden = torch.stack(output_hidden, dim=0).to(\n",
    "            self._device)  # (num_layers, batch_size, num_nodes * rnn_units)\n",
    "        return output_hidden, current_inputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_rnn_layers):\n",
    "            init_states.append(self.encoding_cells[i].init_hidden(batch_size))\n",
    "        # (num_layers, batch_size, num_nodes * rnn_units)\n",
    "        return torch.stack(init_states, dim=0)\n",
    "\n",
    "\n",
    "class DCGRUDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, max_diffusion_step, num_nodes,\n",
    "                 hid_dim, output_dim, num_rnn_layers, dcgru_activation=None,\n",
    "                 filter_type='laplacian', device=None, dropout=0.0):\n",
    "        super(DCGRUDecoder, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        self.output_dim = output_dim\n",
    "        self.num_rnn_layers = num_rnn_layers\n",
    "        self._device = device\n",
    "        self.dropout = dropout\n",
    "\n",
    "        cell = DCGRUCell(input_dim=hid_dim, num_units=hid_dim,\n",
    "                         max_diffusion_step=max_diffusion_step,\n",
    "                         num_nodes=num_nodes, nonlinearity=dcgru_activation,\n",
    "                         filter_type=filter_type)\n",
    "\n",
    "        decoding_cells = list()\n",
    "        # first layer of the decoder\n",
    "        decoding_cells.append(\n",
    "            DCGRUCell(\n",
    "                input_dim=input_dim,\n",
    "                num_units=hid_dim,\n",
    "                max_diffusion_step=max_diffusion_step,\n",
    "                num_nodes=num_nodes,\n",
    "                nonlinearity=dcgru_activation,\n",
    "                filter_type=filter_type))\n",
    "        # construct multi-layer rnn\n",
    "        for _ in range(1, num_rnn_layers):\n",
    "            decoding_cells.append(cell)\n",
    "\n",
    "        self.decoding_cells = nn.ModuleList(decoding_cells)\n",
    "        self.projection_layer = nn.Linear(self.hid_dim, self.output_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)  # dropout before projection layer\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            inputs,\n",
    "            initial_hidden_state,\n",
    "            supports,\n",
    "            teacher_forcing_ratio=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: shape (seq_len, batch_size, num_nodes, output_dim)\n",
    "            initial_hidden_state: the last hidden state of the encoder, shape (num_layers, batch, num_nodes * rnn_units)\n",
    "            supports: list of supports from laplacian or dual_random_walk filters\n",
    "            teacher_forcing_ratio: ratio for teacher forcing\n",
    "        Returns:\n",
    "            outputs: shape (seq_len, batch_size, num_nodes * output_dim)\n",
    "        \"\"\"\n",
    "        seq_length, batch_size, _, _ = inputs.shape\n",
    "        inputs = torch.reshape(inputs, (seq_length, batch_size, -1))\n",
    "\n",
    "        go_symbol = torch.zeros(\n",
    "            (batch_size,\n",
    "             self.num_nodes *\n",
    "             self.output_dim)).to(\n",
    "            self._device)\n",
    "\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(\n",
    "            seq_length,\n",
    "            batch_size,\n",
    "            self.num_nodes *\n",
    "            self.output_dim).to(\n",
    "            self._device)\n",
    "\n",
    "        current_input = go_symbol  # (batch_size, num_nodes * input_dim)\n",
    "        for t in range(seq_length):\n",
    "            next_input_hidden_state = []\n",
    "            for i_layer in range(0, self.num_rnn_layers):\n",
    "                hidden_state = initial_hidden_state[i_layer]\n",
    "                output, hidden_state = self.decoding_cells[i_layer](\n",
    "                    supports, current_input, hidden_state)\n",
    "                current_input = output\n",
    "                next_input_hidden_state.append(hidden_state)\n",
    "            initial_hidden_state = torch.stack(next_input_hidden_state, dim=0)\n",
    "\n",
    "            projected = self.projection_layer(self.dropout(\n",
    "                output.reshape(batch_size, self.num_nodes, -1)))\n",
    "            projected = projected.reshape(\n",
    "                batch_size, self.num_nodes * self.output_dim)\n",
    "            outputs[t] = projected\n",
    "\n",
    "            if teacher_forcing_ratio is not None:\n",
    "                teacher_force = random.random() < teacher_forcing_ratio  # a bool value\n",
    "                current_input = (inputs[t] if teacher_force else projected)\n",
    "            else:\n",
    "                current_input = projected\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "########## Model for next time prediction ##########\n",
    "class DCRNNModel_nextTimePred(nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_dim,\n",
    "                 input_dim, output_dim,\n",
    "                max_diffusion_step=2, num_rnn_layers=1,\n",
    "                cl_decay_steps=3000, dcgru_activation='tanh',\n",
    "                filter_type='laplacian', dropout=0.0,\n",
    "                use_curriculum_learning=False,\n",
    "                device=None):\n",
    "        super(DCRNNModel_nextTimePred, self).__init__()\n",
    "\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_rnn_layers = num_rnn_layers\n",
    "        self.rnn_units = hidden_dim\n",
    "        self._device = device\n",
    "        self.output_dim = output_dim\n",
    "        self.cl_decay_steps = cl_decay_steps # sampling decay steps\n",
    "        self.use_curriculum_learning = bool(use_curriculum_learning)\n",
    "\n",
    "        self.encoder = DCRNNEncoder(input_dim=input_dim,\n",
    "                                    max_diffusion_step=max_diffusion_step,\n",
    "                                    hid_dim=self.rnn_units, num_nodes=num_nodes,\n",
    "                                    num_rnn_layers=num_rnn_layers,\n",
    "                                    dcgru_activation=dcgru_activation,\n",
    "                                    filter_type=filter_type)\n",
    "        self.decoder = DCGRUDecoder(input_dim=output_dim,\n",
    "                                    max_diffusion_step=max_diffusion_step,\n",
    "                                    num_nodes=num_nodes, hid_dim=self.rnn_units,\n",
    "                                    output_dim=output_dim,\n",
    "                                    num_rnn_layers=num_rnn_layers,\n",
    "                                    dcgru_activation=dcgru_activation,\n",
    "                                    filter_type=filter_type,\n",
    "                                    device=device,\n",
    "                                    dropout=dropout)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            encoder_inputs,\n",
    "            decoder_inputs,\n",
    "            supports,\n",
    "            batches_seen=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder_inputs: encoder input sequence, shape (batch, input_seq_len, num_nodes, input_dim)\n",
    "            decoder_inputs: decoder input sequence, shape (batch, output_seq_len, num_nodes, output_dim)\n",
    "            supports: list of adjacency matrices, with length of batch and each element shape (num_nodes, num_nodes)\n",
    "            batches_seen: number of examples seen so far, for teacher forcing\n",
    "        Returns:\n",
    "            outputs: predicted output sequence, shape (batch, output_seq_len, num_nodes, output_dim)\n",
    "        \"\"\"\n",
    "        batch_size, output_seq_len, num_nodes, _ = decoder_inputs.shape\n",
    "        # supports = [support.repeat(batch_size, 1, 1) for support in supports]\n",
    "        if supports[0].shape[0] != batch_size: # last batch may have different batch size\n",
    "            supports = [item[0, :, :].repeat(batch_size, 1, 1) for item in supports]\n",
    "            # print(supports[0].shape, len(supports))\n",
    "\n",
    "        # (seq_len, batch_size, num_nodes, input_dim)\n",
    "        encoder_inputs = torch.transpose(encoder_inputs, dim0=0, dim1=1)\n",
    "        # (seq_len, batch_size, num_nodes, output_dim)\n",
    "        decoder_inputs = torch.transpose(decoder_inputs, dim0=0, dim1=1)\n",
    "\n",
    "        # initialize the hidden state of the encoder\n",
    "        init_hidden_state = self.encoder.init_hidden(batch_size).to(self._device)\n",
    "\n",
    "        # encoder\n",
    "        # (num_layers, batch, rnn_units*num_nodes)\n",
    "        encoder_hidden_state, _ = self.encoder(\n",
    "            encoder_inputs, init_hidden_state, supports)\n",
    "\n",
    "        # decoder\n",
    "        if self.training and self.use_curriculum_learning and (\n",
    "                batches_seen is not None):\n",
    "            teacher_forcing_ratio = compute_sampling_threshold(\n",
    "                self.cl_decay_steps, batches_seen)\n",
    "        else:\n",
    "            teacher_forcing_ratio = None\n",
    "        outputs = self.decoder(\n",
    "            decoder_inputs,\n",
    "            encoder_hidden_state,\n",
    "            supports,\n",
    "            teacher_forcing_ratio=teacher_forcing_ratio)  # (seq_len, batch_size, num_nodes * output_dim)\n",
    "        # (seq_len, batch_size, num_nodes, output_dim)\n",
    "        outputs = outputs.reshape((output_seq_len, batch_size, num_nodes, -1))\n",
    "        # (batch_size, seq_len, num_nodes, output_dim)\n",
    "        outputs = torch.transpose(outputs, dim0=0, dim1=1)\n",
    "\n",
    "        return outputs\n",
    "########## Model for next time prediction ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_wO7_DeZXce",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Here, you are asked to implement different strategies for building the adjacency matrix of the graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used OSRM local server instance to get road network distance among pair of sensors. I followed https://datawookie.dev/blog/2017/09/building-a-local-osrm-instance/ as a reference. Then, the below code connects to the server and retrieves shortest path among all pairs of sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "\n",
    "def get_sensor_dists(sensor_locations):\n",
    "    \"Compute Raw Network Distance between each pair of sensors\"\n",
    "    if not os.path.exists(\"data/pairwise_distances.csv\"):\n",
    "        sensor_locations = sensor_locations.drop(columns=[\"index\"])\n",
    "        results = []\n",
    "\n",
    "        osrm_server_url = \"http://localhost:5000\" \n",
    "\n",
    "        for i, row_from in sensor_locations.iterrows():\n",
    "            for j, row_to in sensor_locations.iterrows():\n",
    "                from_id, to_id = row_from[\"sensor_id\"], row_to[\"sensor_id\"]\n",
    "                if i != j:  \n",
    "                    from_coords = f'{row_from[\"longitude\"]},{row_from[\"latitude\"]}'\n",
    "                    to_coords = f'{row_to[\"longitude\"]},{row_to[\"latitude\"]}'\n",
    "                    # Construct OSRM API query\n",
    "                    route_url = f\"{osrm_server_url}/route/v1/driving/{from_coords};{to_coords}\"\n",
    "                    params = {\n",
    "                        \"overview\": \"false\",  # Don't include the full route geometry\n",
    "                        \"annotations\": \"distance\"  # Get the distance\n",
    "                    }\n",
    "                    response = requests.get(route_url, params=params)\n",
    "                    if response.status_code == 200:\n",
    "                        data = response.json()\n",
    "                        # Extract the distance\n",
    "                        distance = data[\"routes\"][0][\"distance\"]\n",
    "                        results.append({\"from\": from_id, \"to\": to_id, \"distance\": distance})\n",
    "                    else:\n",
    "                        print(f\"Error with {from_id} -> {to_id}: {response.content}\")\n",
    "                else:\n",
    "                    results.append({\"from\": from_id, \"to\": to_id, \"distance\": 0})\n",
    "                    \n",
    "        # Create the final dataframe\n",
    "        distance_df = pd.DataFrame(results)\n",
    "        distance_df.to_csv(\"data/pairwise_distances.csv\", index=False)\n",
    "        \n",
    "        return distance_df\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "T2b0cLYhZY-e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "def calculate_euclidean_adjacency(sensor_locations, threshold):\n",
    "    \"\"\"\n",
    "    Creates an adjacency matrix where nodes are connected based on their Euclidean distance.\n",
    "    Args:\n",
    "        sensor_locations (pd.DataFrame): DataFrame with sensor coordinates (latitude, longitude).\n",
    "        threshold (float): Distance threshold for connectivity; if distance > threshold, set weight to 0.\n",
    "    Returns:\n",
    "        adjacency_matrix (np.array): Adjacency matrix based on Euclidean distances. shape: (num_nodes, num_nodes)\n",
    "    \"\"\"\n",
    "    # TODO: Compute the pairwise Euclidean distance between sensor locations, turn it into similarity scores using Gaussian Kernel\n",
    "    # similar to the approach proposed in the paper\n",
    "    sensor_location_array = sensor_locations.iloc[:, 2:].to_numpy()\n",
    "    dist_matrix = distance_matrix(sensor_location_array, sensor_location_array) # shape: (num_nodes, num_nodes)\n",
    "    # Gaussian Kernel\n",
    "    std = dist_matrix.std()\n",
    "    adjacency_matrix = np.exp(-dist_matrix ** 2 / std ** 2)\n",
    "    adjacency_matrix[adjacency_matrix < threshold] = 0.0\n",
    "    # return the adjacency matrix\n",
    "    # Note: You will need to select a reasonable threshold to result in a reasonably sparse matrix for better performance\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "def calculate_road_network_adjacency(sensor_locations, threshold):\n",
    "    \"\"\"\n",
    "    Creates an adjacency matrix based on shortest path distances in a road network.\n",
    "    Args:\n",
    "        sensor_locations (pd.DataFrame): DataFrame with sensor locations.\n",
    "        threshold (float): Maximum path distance to consider a connection.\n",
    "    Returns:\n",
    "        adjacency_matrix (np.array): Adjacency matrix based on road network distances. shape: (num_nodes, num_nodes)\n",
    "    \"\"\"\n",
    "    # TODO: First, you need to find the road network information in LA, then you need to calculate shortest path distances in the road network, turn it into similarity scores using Gaussian Kernel, return the adjacency matrix\n",
    "    # You also need to select a reasonable distance threshold value to result in a reasonably sparse adjacency matrix for better performance\n",
    "    # Tip: To get road-network information, you can use an approach similar to the previous assignment. Alternatively, similar to the original DCRNN paper, you can use `OSRM local server` to find the driving distance between the sensors.\n",
    "    \n",
    "    sensor_dict = {val['sensor_id']: i for i, val in sensor_locations.iterrows()}\n",
    "    \n",
    "    # Got road network distances from DCRNN repository.\n",
    "    distances_df = pd.read_csv(\"data/pairwise_distances.csv\")\n",
    "    dist_matrix = np.zeros((len(sensor_dict), len(sensor_dict)))\n",
    "    dist_matrix.fill(np.inf) # initialize distances with inf\n",
    "    for _, record in distances_df.iterrows():\n",
    "        if record['from'] in sensor_dict and record['to'] in sensor_dict:\n",
    "            dist_matrix[sensor_dict[record['from']], sensor_dict[record['to']]] = record['distance']\n",
    "    # filter out inf values\n",
    "    non_inf_dists = dist_matrix[dist_matrix != np.inf] \n",
    "    std = non_inf_dists.std()\n",
    "    adjacency_matrix = np.exp(-np.square(dist_matrix / std))\n",
    "    adjacency_matrix[adjacency_matrix < threshold] = 0\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "def calculate_fully_connected_adjacency(num_nodes):\n",
    "  \"\"\"\n",
    "  Creates a fully connected adjacency matrix.\n",
    "  Args:\n",
    "      num_nodes (int): Number of nodes in the graph.\n",
    "  Returns:\n",
    "      adjacency_matrix (np.array): Fully connected adjacency matrix with all entries set to 1. shape: (num_nodes, num_nodes)\n",
    "  \"\"\"\n",
    "  # TODO: Create a fully connected matrix with equal weights\n",
    "  # row stochastic\n",
    "  return np.ones((num_nodes, num_nodes))\n",
    "\n",
    "\n",
    "def calculate_identity_adjacency(num_nodes):\n",
    "    \"\"\"\n",
    "    Creates an identity matrix where only self-loops are present.\n",
    "    Args:\n",
    "        num_nodes (int): Number of nodes in the graph.\n",
    "    Returns:\n",
    "        adjacency_matrix (np.array): Identity matrix. shape: (num_nodes, num_nodes)\n",
    "    \"\"\"\n",
    "    # TODO: Create an identity matrix\n",
    "    return np.eye(num_nodes)\n",
    "\n",
    "\n",
    "def calculate_correlation_adjacency_batch(batch_data, threshold):\n",
    "    \"\"\"\n",
    "    Creates an adjacency matrix for a batch based on the correlation between sensors in the batch.\n",
    "    Args:\n",
    "        batch_data (torch.Tensor): Batch data of shape (batch_size, time_steps, num_nodes, 1).\n",
    "        threshold (float): Minimum correlation required for a connection.\n",
    "    Returns:\n",
    "        adjacency_matrix (torch.Tensor): Correlation-based adjacency matrix for the batch. shape: (batch_size, num_nodes, num_nodes)\n",
    "    \"\"\"\n",
    "    # TODO: calculate the correlations between sensor time series for each sample in the batch\n",
    "    # create an adjacency matrix based on that, get rid of values smaller than a reasonable threshold, return it.\n",
    "    # Tips: There are many different ways to measure similarities between different sequences, some options are cross-correlation, DTW distance, Euclidean distance, Attention mechanism, etc.\n",
    "    # It might also be computationally very slow to calculate these similarities per sample every time during training, you might want to somehow get rid of the repeated calculations across different epochs by caching or some other mechanism.\n",
    "    \n",
    "    batch_size, window_len, num_nodes, _ = batch_data.shape # window_len = num_time_steps\n",
    "    batch_data = batch_data.squeeze(-1) # remove the last dimension (1)\n",
    "    \n",
    "    # # Normalize the data\n",
    "    # batch_data = (batch_data - batch_data.mean(dim=1, keepdim=True)) / (batch_data.std(dim=1, keepdim=True) + 1e-8)\n",
    "    # Calculate the cross-correlation\n",
    "    adjacency_matrix = torch.einsum('bti,btj->bij', batch_data, batch_data) / window_len\n",
    "    # Apply the threshold\n",
    "    adjacency_matrix[adjacency_matrix < threshold] = 0.0\n",
    "    \n",
    "    # laplace normalization\n",
    "    # Compute the degree matrix\n",
    "    degree_matrix = torch.sum(adjacency_matrix, dim=-1)  # Shape: [batch_size, num_nodes]\n",
    "\n",
    "    # Compute D^(-1/2)\n",
    "    degree_matrix_inv_sqrt = torch.diag_embed(degree_matrix.pow(-0.5))  # Shape: [batch_size, num_nodes, num_nodes]\n",
    "    # Compute the Laplacian matrix L = D - A\n",
    "    laplacian_matrix = torch.diag_embed(degree_matrix) - adjacency_matrix  # Shape: [batch_size, num_nodes, num_nodes]\n",
    "\n",
    "    # Compute the normalized Laplacian L_norm = D^(-1/2) * L * D^(-1/2)\n",
    "    normalized_laplacian = torch.matmul(degree_matrix_inv_sqrt, torch.matmul(laplacian_matrix, degree_matrix_inv_sqrt))\n",
    "\n",
    "    return normalized_laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGtDMpdybO7u",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training\n",
    "Next, we set up the train/validation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "k8ELOs4ibK82",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import wandb\n",
    "import tqdm\n",
    "\n",
    "# Loss function and metrics\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Helper function for MAE\n",
    "def mean_absolute_error(y_pred, y_true):\n",
    "    return torch.mean(torch.abs(y_pred - y_true))\n",
    "def mean_absolute_percentage_error(y_pred, y_true):\n",
    "    return torch.mean(torch.abs((y_true - y_pred) / (y_true+1e-8))) * 100\n",
    "def root_mean_squared_error(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "def denormalize_data(data, scaler):\n",
    "    \"\"\"Denormalize the data using the scaler\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): NumPy array of normalized data with shape (batch_size, window_size, num_nodes, 1)\n",
    "        scaler (MinMaxScaler): MinMaxScaler object\n",
    "\n",
    "    Returns:\n",
    "        denormalized_data: Denormalized data based on MinMaxScaler\n",
    "    \"\"\"\n",
    "    # scaler.scale_ has the shape of (num_nodes,)\n",
    "    data_scaler = np.expand_dims(scaler.scale_, axis=(0, 1, 3)) # Add dimensions to match data shape. data_scaler.shape = (1, 1, num_nodes, 1)\n",
    "    data_min = np.expand_dims(scaler.data_min_, axis=(0, 1, 3)) # Add dimensions to match data shape\n",
    "    denormalized_data = np.divide(data + data_min, data_scaler)\n",
    "    return denormalized_data\n",
    "\n",
    "# Training loop with use_corr_based_graph flag\n",
    "def train_epoch(model, train_loader, supports, optimizer, device, use_corr_based_graph):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch_idx, (encoder_inputs, decoder_inputs) in enumerate(train_loader):\n",
    "        encoder_inputs, decoder_inputs = encoder_inputs.to(device), decoder_inputs.to(device)\n",
    "\n",
    "        # Conditionally set supports based on use_corr_based_graph flag\n",
    "        if use_corr_based_graph:\n",
    "            # Calculate correlation adjacency matrix for the current batch\n",
    "            supports = [calculate_correlation_adjacency_batch(encoder_inputs, threshold=0.3).to(device)]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(encoder_inputs, decoder_inputs, supports)\n",
    "        loss = criterion(outputs, decoder_inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss / len(train_loader)\n",
    "\n",
    "# Validation loop with use_corr_based_graph flag\n",
    "def validate_epoch(model, val_loader, supports, device, use_corr_based_graph):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_mae = 0.0\n",
    "    val_mape = 0.0\n",
    "    val_rmse = 0.0\n",
    "    with torch.no_grad():\n",
    "        for encoder_inputs, decoder_inputs in val_loader:\n",
    "            encoder_inputs, decoder_inputs = encoder_inputs.to(device), decoder_inputs.to(device)\n",
    "\n",
    "            # Conditionally set supports based on use_corr_based_graph flag\n",
    "            if use_corr_based_graph:\n",
    "                supports = [calculate_correlation_adjacency_batch(encoder_inputs, threshold=0.3).to(device)]\n",
    "            outputs = model(encoder_inputs, decoder_inputs, supports)\n",
    "            loss = criterion(outputs, decoder_inputs)\n",
    "            \n",
    "            # denormalized_outputs = denormalize_data(outputs.cpu().numpy(), scaler)\n",
    "            # denormalized_decoder_inputs = denormalize_data(decoder_inputs.cpu().numpy(), scaler)\n",
    "            \n",
    "            mae = mean_absolute_error(outputs, decoder_inputs)\n",
    "            mape = mean_absolute_percentage_error(outputs, decoder_inputs)\n",
    "            rmse = root_mean_squared_error(outputs, decoder_inputs)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_mae += mae.item()\n",
    "            val_mape += mape.item()\n",
    "            val_rmse += rmse.item()\n",
    "\n",
    "    return val_loss / len(val_loader), val_mae / len(val_loader), val_mape / len(val_loader), val_rmse / len(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wDEHGGgUaczQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define graph types for experimentation\n",
    "graph_types = [ 'road_network', 'identity', 'euclidean', 'fully_connected', 'corr_based']\n",
    "results = {}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_nodes = sensor_locations.shape[0]\n",
    "\n",
    "# Dictionary to store adjacency matrices for each graph type\n",
    "adjacency_matrices = {}\n",
    "\n",
    "# TODO: Calculate adjacency matrix for each graph type and store in `adjacency_matrices`\n",
    "\n",
    "# 1. Euclidean Distance Adjacency\n",
    "adjacency_matrices['euclidean'] = calculate_euclidean_adjacency(sensor_locations, threshold=0.1)\n",
    "\n",
    "# 2. Road Network Adjacency\n",
    "adjacency_matrices['road_network'] = calculate_road_network_adjacency(sensor_locations, threshold=0.1)\n",
    "\n",
    "# 3. Fully Connected Graph\n",
    "adjacency_matrices['fully_connected'] = calculate_fully_connected_adjacency(num_nodes)\n",
    "\n",
    "# 4. Identity (Fully Disconnected) Graph\n",
    "adjacency_matrices['identity'] = calculate_identity_adjacency(num_nodes)\n",
    "\n",
    "# 5. Correlation-Based Adjacency (Dynamic, calculated per batch)\n",
    "adjacency_matrices['corr_based'] = None  # Set to None for dynamic calculation in training loop\n",
    "# Please note that you need to calculate the correlation-based adjacency matrix in the training loop by setting use_corr_based_graph flag set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"CSCI587_HW3.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unnormalized, bs=64, fixed_lr=0.001, h=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcxIy0b9kbpy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tank/users/bita/CSCI_587/HW3/wandb/run-20241201_125525-sly7qpsf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/sly7qpsf' target=\"_blank\">euclidean-fixed-lr_0.001-horizon_3-unnormalized-bs_32-patience_45-wd_0-epochs_100-hidden_64-rnn_1-dropout_0.0-optimizer_Adam-AMSGrad_True</a></strong> to <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/sly7qpsf' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN/runs/sly7qpsf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with euclidean adjacency matrix...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:28<46:33, 28.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 0: Test loss = 40.65, Test MAE = 40.65, Test MAPE = 4377724607.44, Test RMSE = 42.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 11/100 [03:38<26:05, 17.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 10: Test loss = 10.29, Test MAE = 10.29, Test MAPE = 15985554266.94, Test RMSE = 16.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 21/100 [06:26<22:25, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 20: Test loss = 9.78, Test MAE = 9.78, Test MAPE = 16311595275.11, Test RMSE = 16.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 31/100 [09:14<19:39, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 30: Test loss = 9.77, Test MAE = 9.77, Test MAPE = 16325044090.02, Test RMSE = 16.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 41/100 [12:02<16:51, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 40: Test loss = 9.41, Test MAE = 9.41, Test MAPE = 15042365955.22, Test RMSE = 14.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 51/100 [14:48<13:52, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 50: Test loss = 9.73, Test MAE = 9.73, Test MAPE = 16117505128.20, Test RMSE = 16.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 61/100 [17:36<11:09, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 60: Test loss = 9.39, Test MAE = 9.39, Test MAPE = 15600157082.52, Test RMSE = 15.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 71/100 [20:23<08:14, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 70: Test loss = 9.46, Test MAE = 9.46, Test MAPE = 15906613140.22, Test RMSE = 15.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 81/100 [23:11<05:25, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 80: Test loss = 9.36, Test MAE = 9.36, Test MAPE = 15804915159.34, Test RMSE = 15.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 91/100 [25:59<02:34, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 90: Test loss = 9.22, Test MAE = 9.22, Test MAPE = 15484292901.61, Test RMSE = 15.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [28:27<00:00, 17.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss for euclidean adjacency: 8.2676\n",
      "Traffic forecasting with euclidean adjacency: Test loss = 9.5663, Test MAE= 9.5663, Test MAPE = 15499285345.5124, Test RMSE = 15.2860\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 7.0%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>test_mae</td><td></td></tr><tr><td>test_mape</td><td></td></tr><tr><td>test_rmse</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_loss</td><td></td></tr><tr><td>val_mae</td><td></td></tr><tr><td>val_mape</td><td></td></tr><tr><td>val_rmse</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>8.26761</td></tr><tr><td>test_loss</td><td>9.56628</td></tr><tr><td>test_mae</td><td>9.56628</td></tr><tr><td>test_mape</td><td>15499285345.51244</td></tr><tr><td>test_rmse</td><td>15.28603</td></tr><tr><td>train_loss</td><td>8.56109</td></tr><tr><td>val_loss</td><td>9.02733</td></tr><tr><td>val_mae</td><td>9.02733</td></tr><tr><td>val_mape</td><td>10725132419.7999</td></tr><tr><td>val_rmse</td><td>14.06957</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">euclidean-fixed-lr_0.001-horizon_3-unnormalized-bs_32-patience_45-wd_0-epochs_100-hidden_64-rnn_1-dropout_0.0-optimizer_Adam-AMSGrad_True</strong> at: <a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/sly7qpsf' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN/runs/sly7qpsf</a><br/> View project at: <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_125525-sly7qpsf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tank/users/bita/CSCI_587/HW3/wandb/run-20241201_132405-gyazmuz0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/gyazmuz0' target=\"_blank\">road_network-fixed-lr_0.001-horizon_3-unnormalized-bs_32-patience_45-wd_0-epochs_100-hidden_64-rnn_1-dropout_0.0-optimizer_Adam-AMSGrad_True</a></strong> to <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/gyazmuz0' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN/runs/gyazmuz0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with road_network adjacency matrix...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:18<30:16, 18.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 0: Test loss = 15.51, Test MAE = 15.51, Test MAPE = 6893729167.97, Test RMSE = 16.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 11/100 [03:05<25:22, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 10: Test loss = 3.24, Test MAE = 3.24, Test MAPE = 1875120936.49, Test RMSE = 6.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 21/100 [05:52<22:28, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 20: Test loss = 3.16, Test MAE = 3.16, Test MAPE = 1456920204.28, Test RMSE = 6.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 31/100 [08:40<19:40, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 30: Test loss = 3.15, Test MAE = 3.15, Test MAPE = 1578437020.71, Test RMSE = 6.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 41/100 [11:27<16:52, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 40: Test loss = 3.09, Test MAE = 3.09, Test MAPE = 1417037222.55, Test RMSE = 5.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 51/100 [14:14<13:52, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 50: Test loss = 3.15, Test MAE = 3.15, Test MAPE = 1500162257.31, Test RMSE = 5.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 61/100 [17:00<11:05, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 60: Test loss = 3.06, Test MAE = 3.06, Test MAPE = 1444189512.75, Test RMSE = 5.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 71/100 [19:48<08:15, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 70: Test loss = 3.04, Test MAE = 3.04, Test MAPE = 1315376695.13, Test RMSE = 5.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 81/100 [22:34<05:23, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 80: Test loss = 3.14, Test MAE = 3.14, Test MAPE = 1340763884.83, Test RMSE = 6.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 91/100 [25:22<02:33, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 90: Test loss = 3.00, Test MAE = 3.00, Test MAPE = 1209344176.00, Test RMSE = 5.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [27:50<00:00, 16.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss for road_network adjacency: 2.8428\n",
      "Traffic forecasting with road_network adjacency: Test loss = 2.9674, Test MAE= 2.9674, Test MAPE = 1257881007.7214, Test RMSE = 5.8975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 7.1%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>test_mae</td><td></td></tr><tr><td>test_mape</td><td></td></tr><tr><td>test_rmse</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_loss</td><td></td></tr><tr><td>val_mae</td><td></td></tr><tr><td>val_mape</td><td></td></tr><tr><td>val_rmse</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>2.84285</td></tr><tr><td>test_loss</td><td>2.96745</td></tr><tr><td>test_mae</td><td>2.96745</td></tr><tr><td>test_mape</td><td>1257881007.72139</td></tr><tr><td>test_rmse</td><td>5.89748</td></tr><tr><td>train_loss</td><td>2.87365</td></tr><tr><td>val_loss</td><td>2.86351</td></tr><tr><td>val_mae</td><td>2.86351</td></tr><tr><td>val_mape</td><td>1117448240.55736</td></tr><tr><td>val_rmse</td><td>5.6808</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">road_network-fixed-lr_0.001-horizon_3-unnormalized-bs_32-patience_45-wd_0-epochs_100-hidden_64-rnn_1-dropout_0.0-optimizer_Adam-AMSGrad_True</strong> at: <a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/gyazmuz0' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN/runs/gyazmuz0</a><br/> View project at: <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_132405-gyazmuz0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tank/users/bita/CSCI_587/HW3/wandb/run-20241201_135208-t5ao5uqv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/t5ao5uqv' target=\"_blank\">fully_connected-fixed-lr_0.001-horizon_3-unnormalized-bs_32-patience_45-wd_0-epochs_100-hidden_64-rnn_1-dropout_0.0-optimizer_Adam-AMSGrad_True</a></strong> to <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/t5ao5uqv' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN/runs/t5ao5uqv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with fully_connected adjacency matrix...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:18<30:16, 18.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 0: Test loss = 45.12, Test MAE = 45.12, Test MAPE = 3121762040.97, Test RMSE = 47.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 11/100 [03:05<25:21, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 10: Test loss = 21.21, Test MAE = 21.21, Test MAPE = 10990103563.60, Test RMSE = 26.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 21/100 [05:51<22:18, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 20: Test loss = 17.12, Test MAE = 17.12, Test MAPE = 13129589301.42, Test RMSE = 23.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 31/100 [08:38<19:34, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 30: Test loss = 15.49, Test MAE = 15.49, Test MAPE = 13684012831.68, Test RMSE = 21.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 41/100 [11:25<16:52, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 40: Test loss = 14.08, Test MAE = 14.08, Test MAPE = 14238494035.70, Test RMSE = 19.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 51/100 [14:12<13:52, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 50: Test loss = 12.78, Test MAE = 12.78, Test MAPE = 14690958161.95, Test RMSE = 17.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 61/100 [16:59<11:02, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 60: Test loss = 11.66, Test MAE = 11.66, Test MAPE = 15088892019.76, Test RMSE = 16.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 71/100 [19:46<08:16, 17.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 70: Test loss = 11.01, Test MAE = 11.01, Test MAPE = 15421839157.54, Test RMSE = 16.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 81/100 [22:33<05:24, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 80: Test loss = 10.32, Test MAE = 10.32, Test MAPE = 15787213701.25, Test RMSE = 16.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 91/100 [25:19<02:32, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 90: Test loss = 9.96, Test MAE = 9.96, Test MAPE = 16024542042.03, Test RMSE = 16.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [27:47<00:00, 16.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss for fully_connected adjacency: 9.2384\n",
      "Traffic forecasting with fully_connected adjacency: Test loss = 9.8439, Test MAE= 9.8439, Test MAPE = 16159041025.3731, Test RMSE = 16.2214\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 9.9%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>test_mae</td><td></td></tr><tr><td>test_mape</td><td></td></tr><tr><td>test_rmse</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_loss</td><td></td></tr><tr><td>val_mae</td><td></td></tr><tr><td>val_mape</td><td></td></tr><tr><td>val_rmse</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>9.23837</td></tr><tr><td>test_loss</td><td>9.84395</td></tr><tr><td>test_mae</td><td>9.84395</td></tr><tr><td>test_mape</td><td>16159041025.37313</td></tr><tr><td>test_rmse</td><td>16.2214</td></tr><tr><td>train_loss</td><td>8.94883</td></tr><tr><td>val_loss</td><td>9.23837</td></tr><tr><td>val_mae</td><td>9.23837</td></tr><tr><td>val_mape</td><td>11185256985.09426</td></tr><tr><td>val_rmse</td><td>14.93428</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fully_connected-fixed-lr_0.001-horizon_3-unnormalized-bs_32-patience_45-wd_0-epochs_100-hidden_64-rnn_1-dropout_0.0-optimizer_Adam-AMSGrad_True</strong> at: <a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/t5ao5uqv' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN/runs/t5ao5uqv</a><br/> View project at: <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_135208-t5ao5uqv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tank/users/bita/CSCI_587/HW3/wandb/run-20241201_142008-wvtvjep7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/wvtvjep7' target=\"_blank\">identity-fixed-lr_0.001-horizon_3-unnormalized-bs_32-patience_45-wd_0-epochs_100-hidden_64-rnn_1-dropout_0.0-optimizer_Adam-AMSGrad_True</a></strong> to <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/wvtvjep7' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN/runs/wvtvjep7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with identity adjacency matrix...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:18<30:15, 18.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 0: Test loss = 13.22, Test MAE = 13.22, Test MAPE = 818091646.12, Test RMSE = 14.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 11/100 [03:06<25:27, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 10: Test loss = 2.85, Test MAE = 2.85, Test MAPE = 1026538936.11, Test RMSE = 5.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 21/100 [05:54<22:28, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 20: Test loss = 2.84, Test MAE = 2.84, Test MAPE = 1029187598.17, Test RMSE = 5.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 31/100 [08:40<19:31, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 30: Test loss = 2.83, Test MAE = 2.83, Test MAPE = 1022503594.96, Test RMSE = 5.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 41/100 [11:28<16:51, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 40: Test loss = 2.83, Test MAE = 2.83, Test MAPE = 1019723254.42, Test RMSE = 5.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 51/100 [14:13<13:40, 16.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 50: Test loss = 2.86, Test MAE = 2.86, Test MAPE = 1023392795.60, Test RMSE = 5.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 61/100 [17:00<11:00, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 60: Test loss = 2.83, Test MAE = 2.83, Test MAPE = 1022922181.76, Test RMSE = 5.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 71/100 [19:46<08:10, 16.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 70: Test loss = 2.83, Test MAE = 2.83, Test MAPE = 1016271951.73, Test RMSE = 5.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 81/100 [22:33<05:23, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 80: Test loss = 2.82, Test MAE = 2.82, Test MAPE = 1021901672.96, Test RMSE = 5.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 91/100 [25:20<02:35, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 90: Test loss = 2.83, Test MAE = 2.83, Test MAPE = 1021410788.71, Test RMSE = 5.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [27:50<00:00, 16.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss for identity adjacency: 2.7426\n",
      "Traffic forecasting with identity adjacency: Test loss = 2.8249, Test MAE= 2.8249, Test MAPE = 1026044561.2948, Test RMSE = 5.9358\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 7.1%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>test_mae</td><td></td></tr><tr><td>test_mape</td><td></td></tr><tr><td>test_rmse</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_loss</td><td></td></tr><tr><td>val_mae</td><td></td></tr><tr><td>val_mape</td><td></td></tr><tr><td>val_rmse</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>2.74256</td></tr><tr><td>test_loss</td><td>2.82494</td></tr><tr><td>test_mae</td><td>2.82494</td></tr><tr><td>test_mape</td><td>1026044561.29478</td></tr><tr><td>test_rmse</td><td>5.93583</td></tr><tr><td>train_loss</td><td>2.7504</td></tr><tr><td>val_loss</td><td>2.74648</td></tr><tr><td>val_mae</td><td>2.74648</td></tr><tr><td>val_mape</td><td>1024790775.99599</td></tr><tr><td>val_rmse</td><td>5.7402</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">identity-fixed-lr_0.001-horizon_3-unnormalized-bs_32-patience_45-wd_0-epochs_100-hidden_64-rnn_1-dropout_0.0-optimizer_Adam-AMSGrad_True</strong> at: <a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/wvtvjep7' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN/runs/wvtvjep7</a><br/> View project at: <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_142008-wvtvjep7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tank/users/bita/CSCI_587/HW3/wandb/run-20241201_144811-etq25318</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/etq25318' target=\"_blank\">corr_based-fixed-lr_0.001-horizon_3-unnormalized-bs_32-patience_45-wd_0-epochs_100-hidden_64-rnn_1-dropout_0.0-optimizer_Adam-AMSGrad_True</a></strong> to <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/etq25318' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN/runs/etq25318</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with corr_based adjacency matrix...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:18<30:57, 18.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 0: Test loss = 43.73, Test MAE = 43.73, Test MAPE = 861678566.38, Test RMSE = 46.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 11/100 [03:11<26:00, 17.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 10: Test loss = 9.31, Test MAE = 9.31, Test MAPE = 3923585351.12, Test RMSE = 13.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 21/100 [06:02<23:03, 17.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 20: Test loss = 8.27, Test MAE = 8.27, Test MAPE = 3879520641.01, Test RMSE = 13.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 31/100 [08:52<19:47, 17.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 30: Test loss = 8.25, Test MAE = 8.25, Test MAPE = 3791074886.78, Test RMSE = 12.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 41/100 [11:41<17:02, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 40: Test loss = 8.24, Test MAE = 8.24, Test MAPE = 3809153362.19, Test RMSE = 12.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 51/100 [14:31<14:07, 17.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 50: Test loss = 8.50, Test MAE = 8.50, Test MAPE = 4010136653.69, Test RMSE = 13.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 61/100 [17:19<11:10, 17.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at epoch 60: Test loss = 8.39, Test MAE = 8.39, Test MAPE = 3933337557.96, Test RMSE = 13.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 67/100 [19:15<09:29, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 67 with patience 45. Best validation loss: 7.8508\n",
      "Best validation loss for corr_based adjacency: 7.8508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic forecasting with corr_based adjacency: Test loss = 8.1921, Test MAE= 8.1921, Test MAPE = 3798527024.7244, Test RMSE = 12.9206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 7.1%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>test_mae</td><td></td></tr><tr><td>test_mape</td><td></td></tr><tr><td>test_rmse</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_loss</td><td></td></tr><tr><td>val_mae</td><td></td></tr><tr><td>val_mape</td><td></td></tr><tr><td>val_rmse</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>7.85084</td></tr><tr><td>test_loss</td><td>8.19211</td></tr><tr><td>test_mae</td><td>8.19211</td></tr><tr><td>test_mape</td><td>3798527024.7244</td></tr><tr><td>test_rmse</td><td>12.92065</td></tr><tr><td>train_loss</td><td>7.72924</td></tr><tr><td>val_loss</td><td>7.94594</td></tr><tr><td>val_mae</td><td>7.94594</td></tr><tr><td>val_mape</td><td>3252733280.73788</td></tr><tr><td>val_rmse</td><td>12.3617</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">corr_based-fixed-lr_0.001-horizon_3-unnormalized-bs_32-patience_45-wd_0-epochs_100-hidden_64-rnn_1-dropout_0.0-optimizer_Adam-AMSGrad_True</strong> at: <a href='https://wandb.ai/bitaazarijoo/DCRNN/runs/etq25318' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN/runs/etq25318</a><br/> View project at: <a href='https://wandb.ai/bitaazarijoo/DCRNN' target=\"_blank\">https://wandb.ai/bitaazarijoo/DCRNN</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_144811-etq25318/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameters - TODO: You need to tune these and achieve a good balance between performance / train time\n",
    "hidden_dim = 64\n",
    "learning_rate = 0.001\n",
    "max_diffusion_step = 2 # You can leave this as is\n",
    "num_rnn_layers = 1\n",
    "dropout = 0.0\n",
    "num_epochs = 100\n",
    "# step_size_lr_scheduler = 20\n",
    "lr_decay_ratio = 0.1\n",
    "weight_decay = 0\n",
    "patience = 45\n",
    "AMSGrad_enabled = True\n",
    "DCRNN_eps = 1e-3\n",
    "test_epoch = 10 # Test the model every 10 epochs\n",
    "\n",
    "# Loop over each graph type to train and evaluate the model\n",
    "for graph_type in graph_types: # TODO: replace with graph_types\n",
    "    # initialize wandb\n",
    "    wandb.init(project=\"DCRNN\", name=f\"{graph_type}-fixed-lr_{learning_rate}-horizon_{horizon}-unnormalized-bs_{batch_size}-patience_{patience}-wd_{weight_decay}-epochs_{num_epochs}-hidden_{hidden_dim}-rnn_{num_rnn_layers}-dropout_{dropout}-optimizer_Adam-AMSGrad_{AMSGrad_enabled}\")\n",
    "    print(f\"\\nTraining with {graph_type} adjacency matrix...\\n\")\n",
    "\n",
    "    # TODO: Retrieve the adjacency matrix for the current `graph_type`\n",
    "    # Supports is the adjacency matrix, with the shape [(batch_size, num_node, num_nodes)]\n",
    "    supports = [torch.tensor(adjacency_matrices.get(graph_type)).to(device).float().repeat(batch_size, 1, 1) if adjacency_matrices.get(graph_type) is not None else None]\n",
    "    use_corr_based_graph = (graph_type == 'corr_based')\n",
    "    # Set up the model and optimizer\n",
    "    model = DCRNNModel_nextTimePred(\n",
    "        num_nodes=num_nodes,\n",
    "        hidden_dim=hidden_dim,\n",
    "        input_dim=1,\n",
    "        output_dim=1,\n",
    "        max_diffusion_step=max_diffusion_step if graph_type != 'identity' else 0,\n",
    "        num_rnn_layers=num_rnn_layers,\n",
    "        dropout=dropout,\n",
    "        use_curriculum_learning=False,\n",
    "        device=device,\n",
    "    ).to(device)\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate,  weight_decay=weight_decay, amsgrad=AMSGrad_enabled, betas=(0.9, 0.99), eps=DCRNN_eps)\n",
    "    # scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 30, 40, 50], gamma=lr_decay_ratio)\n",
    "    # Track best validation loss and model state for each graph type\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience_cnt = 0\n",
    "    # Training loop for multiple epochs\n",
    "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "        # TODO: Train model for one epoch and calculate training loss, e.g.,\n",
    "        train_loss = train_epoch(model, train_loader, supports, optimizer, device, use_corr_based_graph)\n",
    "\n",
    "        # TODO: Evaluate model on validation set and calculate validation loss and MAE\n",
    "        val_loss, val_mae, val_mape, val_rmse = validate_epoch(model, val_loader, supports, device, use_corr_based_graph)\n",
    "        # scheduler.step()\n",
    "        \n",
    "        # Log training and validation loss\n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss, \"val_mae\": val_mae, \"val_mape\": val_mape, \"val_rmse\": val_rmse})\n",
    "\n",
    "        # TODO: Save the model state if validation loss improves\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            wandb.log({\"best_val_loss\": best_val_loss})\n",
    "            patience_cnt = 0\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "            if patience_cnt >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch} with patience {patience}. Best validation loss: {best_val_loss:.4f}\")\n",
    "                break\n",
    "            \n",
    "        if epoch % test_epoch == 0:\n",
    "            test_loss, test_mae, test_mape, test_rmse = validate_epoch(model, test_loader, supports, device, use_corr_based_graph)\n",
    "            # wandb.log({\"test_loss\": test_loss, \"test_mae\": test_mae, \"test_mape\": test_mape, \"test_rmse\": test_rmse})\n",
    "            print(f\"Testing at epoch {epoch}: Test loss = {test_loss:.2f}, Test MAE = {test_mae:.2f}, Test MAPE = {test_mape:.2f}, Test RMSE = {test_rmse:.2f}\")\n",
    "    \n",
    "    # TODO: Store the best validation loss and model state for the current graph type in `results`\n",
    "    results[graph_type] = {\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"best_model_state\": best_model_state\n",
    "    }\n",
    "\n",
    "    print(f\"Best validation loss for {graph_type} adjacency: {best_val_loss:.4f}\")\n",
    "    \n",
    "\n",
    "    # Load the best model state for the current graph type\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # TODO: Test the model on the test set and calculate test loss and MAE\n",
    "    test_loss, test_mae, test_mape, test_rmse = validate_epoch(model, test_loader, supports, device, use_corr_based_graph)\n",
    "\n",
    "    # TODO: Store the best validation loss, test loss, and model state for the current graph type in `results`\n",
    "    results[graph_type] = {\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_mae\": test_mae,\n",
    "        \"test_mape\": test_mape,\n",
    "        \"test_rmse\": test_rmse,\n",
    "        \"best_model_state\": best_model_state\n",
    "    }\n",
    "    wandb.log({\"test_loss\": test_loss, \"test_mae\": test_mae, \"test_mape\": test_mape, \"test_rmse\": test_rmse})\n",
    "    print(f\"Traffic forecasting with {graph_type} adjacency: Test loss = {test_loss:.4f}, Test MAE= {test_mae:.4f}, Test MAPE = {test_mape:.4f}, Test RMSE = {test_rmse:.4f}\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGaK0xP2lzl4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Discussion\n",
    "TODO: For this part, please:\n",
    "- Compare results across graph types and summarize your findings. You can visualize the test/validation performance for different graph types to support your findings.\n",
    "- Discuss which graph type performed best on the test set, and justify why.\n",
    "- Discuss why some adjacency matrices resulted in better performacne compared to the other ones.\n",
    "- Describe how you tuned the training hyperparameters.\n",
    "- In case you had any interesting observations or faced some challenges, please also describe those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance and graph types:** The results indicate that using the `identity` adjacency matrix yields the best performance. While this might seem counterintuitive initially, it aligns with expectations because the traffic data was not normalized. Traffic recordings have high values (e.g., 60-70), causing model parameters to become large and leading to the gradient explosion problem. As a result, GNN message passing becomes less effective and does not capture inter-sensor dependencies effectively.\n",
    "\n",
    "Beyond this, other observations align with expectations. The `road_network` adjacency matrix performs the best among all remaining adjacency matrices, effectively capturing spatial dependencies. It outperforms the euclidean adjacency matrix, as evidenced by lower MAE and RMSE on both validation and test sets. This supports the intuition behind DCRNN: Euclidean distance is not a reliable estimate for road network distance. Plots of MAE and RMSE on the validation and test sets illustrate this clearly.\n",
    "\n",
    "The `fully_connected` adjacency matrix performed the worst, as anticipated. Its inefficiency stems from message passing within a complete graph, where all nodes exchange information with every other node. This diminishes the graph's ability to capture meaningful contextual information from traffic data.\n",
    "\n",
    "For the `corr_based` adjacency matrix, cross-correlation between time series was used, but it failed to reflect true temporal correlations among sensors. More sophisticated methods, such as Dynamic Time Warping (DTW) or attention-based mechanisms on time series embeddings might improve results.\n",
    "\n",
    "Overall, while the identity and road_network adjacency matrices show comparable performance, other adjacency matrices fail to effectively capture spatiotemporal relationships in the data.\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "    <img src=\"fig/val_mae.png\" alt=\"Image 1\" style=\"width: 45%;height: 300px;\"/>\n",
    "    <img src=\"fig/val_rmse.png\" alt=\"Image 2\" style=\"width: 45%;height: 300px;\"/>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "    <img src=\"fig/test_mae.png\" alt=\"Image 3\" style=\"width: 45%;\"/>\n",
    "    <img src=\"fig/test_rmse.png\" alt=\"Image 4\" style=\"width: 45%;\"/>\n",
    "</div>\n",
    "\n",
    "**Hyperparameter Tuning:** I used `wandb` to see the results of each run and tune hyperparameters. I found out that setting `batch_size=64` and `dropout=0` gives best results. Also, I applied early stopping with `patience=45` to avoid running DCRNN too long when there is not any improvement on validation loss.\n",
    "\n",
    "**Miscellaneous:** The most important challenge was trying to reproduce DCRNN paper results, but then I found out the setting here was different. Data (traffic time series and adjacency matrices) was not normalized, `dual_random_walk` was not used. After this observation, I realized it is expected because this setting leads to gradient explosion and having all 1 values for each sensor and each paying attention to its intra-representation makes more sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxPwBhIX1bB4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Submission Instructions\n",
    "Please submit your completed Jupyter Notebook file as `HW3_YourName_USC_ID.ipynb` on Brightspace. Make sure all the cells have been successfully executed and the outputs are visible."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MulEHR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
